{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadirectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A __metadirective__ directive provides a mechanism to select a directive in a __when__ clause to be used, depending upon one or more contexts:   implementation, available devices and the present enclosing construct.  The directive in an __otherwise__ clause is used when a directive of the  __when__ clause is not selected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the __when__ clause the  _context selector_  (or just  _selector_ ) defines traits that are evaluated for selection of the directive that follows the selector.  This \"selectable\" directive is called a  _directive variant_ . Traits are grouped by  _construct_ ,  _implementation_  and   _device_   _sets_  to be used by a selector of the same name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first example the architecture trait  _arch_  of the   _device_  selector set specifies that if an  _nvptx_  architecture is active in the OpenMP context, then the __teams__ __loop__   _directive variant_  is selected as the directive; otherwise, the __parallel__ __loop__  _directive variant_  of the __otherwise__ clause is selected as the directive. That is, if a  _device_  of  _nvptx_  architecture is supported by the implementation within the enclosing __target__ construct, its  _directive variant_  is selected. The architecture names, such as  _nvptx_ , are implementation defined. Also, note that  _device_  as used in a __target__ construct specifies a device number, while  _device_ , as used in the __metadirective__ directive as selector set, has traits of  _kind_ ,  _isa_  and  _arch_ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//%compiler: clang\n",
    "//%cflags: -fopenmp\n",
    "\n",
    "/*\n",
    "* name: metadirective.1\n",
    "* type: C\n",
    "* version: omp_5.2\n",
    "*/\n",
    "\n",
    "#define N 100\n",
    "#include <stdio.h>\n",
    "\n",
    "int main()\n",
    "{\n",
    "   int v1[N], v2[N], v3[N];\n",
    "   for(int i=0; i<N; i++){ v1[i]=(i+1); v2[i]=-(i+1); }\n",
    "\n",
    "   #pragma omp target map(to:v1,v2) map(from:v3) device(0)\n",
    "   #pragma omp metadirective \\\n",
    "                   when(     device={arch(\"nvptx\")}: teams loop) \\\n",
    "                   otherwise(                     parallel loop)\n",
    "     for (int i= 0; i< N; i++)  v3[i] = v1[i] * v2[i];\n",
    "\n",
    "   printf(\" %d  %d\\n\",v3[0],v3[N-1]); //output: -1  -10000\n",
    "\n",
    "   return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!!%compiler: gfortran\n",
    "!!%cflags: -fopenmp\n",
    "\n",
    "! name: metadirective.1\n",
    "! type: F-free\n",
    "! version: omp_5.2\n",
    "program main\n",
    "   integer, parameter :: N= 100\n",
    "   integer ::  v1(N), v2(N), v3(N);\n",
    "\n",
    "   do i=1,N;  v1(i)=i; v2(i)=-i;  enddo   ! initialize\n",
    "\n",
    "   !$omp  target map(to:v1,v2) map(from:v3) device(0)\n",
    "   !$omp  metadirective &\n",
    "   !$omp&     when(     device={arch(\"nvptx\")}: teams loop) &\n",
    "   !$omp&     otherwise(                     parallel loop)\n",
    "     do i= 1,N; v3(i) = v1(i) * v2(i); enddo\n",
    "   !$omp  end target\n",
    "\n",
    "   print *, v3(1),v3(N) !!output: -1  -10000\n",
    "end program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the second example, the  _implementation_  selector set is specified in the __when__ clause to distinguish between platforms.  Additionally, specific architectures are specified with the  _device_   selector set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code, different __teams__ constructs are employed as determined by the __metadirective__ directive. The number of teams is restricted by a __num_teams__ clause and a thread limit is also set by a __thread_limit__ clause for   _vendor_  platforms and specific architecture traits.  Otherwise, just the __teams__ construct is used without any clauses, as prescribed by the __otherwise__ clause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//%compiler: clang\n",
    "//%cflags: -fopenmp\n",
    "\n",
    "/*\n",
    "* name: metadirective.2\n",
    "* type: C\n",
    "* version: omp_5.2\n",
    "*/\n",
    "#define N 100\n",
    "#include <stdio.h>\n",
    "#include <omp.h>\n",
    "\n",
    "void work_on_chunk(int idev, int i);\n",
    "\n",
    "int main()                    //Driver\n",
    "{\n",
    "   int i,idev;\n",
    "\n",
    "   for (idev=0; idev<omp_get_num_devices(); idev++)\n",
    "   {\n",
    "      #pragma omp target device(idev)\n",
    "      #pragma omp metadirective \\\n",
    "               when( implementation={vendor(nvidia)},            \\\n",
    "                                       device={arch(\"kepler\")}:  \\\n",
    "                     teams num_teams(512) thread_limit(32) )     \\\n",
    "               when( implementation={vendor(amd)},               \\\n",
    "                                       device={arch(\"fiji\"  )}:  \\\n",
    "                     teams num_teams(512) thread_limit(64) )     \\\n",
    "               otherwise(                                        \\\n",
    "                     teams)\n",
    "      #pragma omp distribute parallel for\n",
    "      for (i=0; i<N; i++) work_on_chunk(idev,i);\n",
    "   }\n",
    "   return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!!%compiler: gfortran\n",
    "!!%cflags: -fopenmp\n",
    "\n",
    "! name: metadirective.2\n",
    "! type: F-free\n",
    "! version: omp_5.2\n",
    "program main                    !!Driver\n",
    "  use omp_lib\n",
    "  implicit none\n",
    "  integer, parameter :: N=1000\n",
    "  external           :: work_on_chunk\n",
    "  integer            :: i,idev\n",
    "\n",
    "  do idev=0,omp_get_num_devices()-1\n",
    "\n",
    "    !$omp target device(idev)\n",
    "    !$omp begin metadirective &\n",
    "    !$omp&  when( implementation={vendor(nvidia)},        &\n",
    "    !$omp&           device={arch(\"kepler\")}:             &\n",
    "    !$omp&        teams num_teams(512) thread_limit(32) ) &\n",
    "    !$omp&  when( implementation={vendor(amd)},           &\n",
    "    !$omp&           device={arch(\"fiji\"  )}:             &\n",
    "    !$omp&        teams num_teams(512) thread_limit(64) ) &\n",
    "    !$omp&  otherwise( teams )\n",
    "    !$omp distribute parallel do\n",
    "    do i=1,N\n",
    "       call work_on_chunk(idev,i)\n",
    "    end do\n",
    "    !$omp end metadirective\n",
    "    !$omp end target\n",
    "\n",
    "  end do\n",
    "\n",
    "end program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the third example, a  _construct_  selector set is specified in the __when__ clause.   Here, a __metadirective__ directive is used within a function that is also compiled as a function for a target device as directed by a declare target directive. The  _target_  directive name of the __construct__ selector ensures that the __distribute__ __parallel__ __for/do__ construct is employed for the target compilation. Otherwise, for the host-compiled version the __parallel__ __for/do__ __simd__ construct is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first call to the  _exp_pi_diff()_  routine the context is a __target__ __teams__ construct and the __distribute__ __parallel__ __for/do__ construct version of the function is invoked, while in the second call the __parallel__ __for/do__ __simd__ construct version is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This case illustrates an important point for users that may want to hoist the  __target__ directive out of a function that contains the usual  __target__ __teams__ __distribute__ __parallel__ __for/do__ construct (for providing alternate constructs through the __metadirective__ directive as here). While this combined construct can be decomposed into a __target__ and __teams distribute parallel for/do__ constructs, the OpenMP 5.0 specification has the restriction: \"If a __teams__ construct is nested within a __target__ construct, that __target__ construct must contain no statements, declarations or directives outside of the __teams__ construct''. So, the __teams__ construct must immediately follow the __target__ construct without any intervening code statements (which includes function calls).   Since the __target__ construct alone cannot be hoisted out of a function,  the __target__ __teams__ construct has been hoisted out of the function, and the  __distribute__ __parallel__ __for/do__ construct is used as the  _variant_  directive of the __metadirective__ directive within the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//%compiler: clang\n",
    "//%cflags: -fopenmp\n",
    "\n",
    "/*\n",
    "* name: metadirective.3\n",
    "* type: C\n",
    "* version: omp_5.2\n",
    "*/\n",
    "#include <stdio.h>\n",
    "#include  <math.h>\n",
    "#define      N 1000\n",
    "\n",
    "#pragma omp begin declare target\n",
    "void exp_pi_diff(double *d, double my_pi){\n",
    "   #pragma omp metadirective \\\n",
    "               when(   construct={target}: distribute parallel for ) \\\n",
    "               otherwise(                  parallel for simd )\n",
    "   for(int i = 0; i<N; i++) d[i] = exp( (M_PI-my_pi)*i );\n",
    "}\n",
    "#pragma omp end declare target\n",
    "\n",
    "int main()\n",
    "{\n",
    "  //Calculates sequence of exponentials: (M_PI-my_pi) * index\n",
    "  //M_PI is from math.h, and my_pi is user provided.\n",
    "\n",
    "  double d[N];\n",
    "  double my_pi=3.14159265358979e0;\n",
    "\n",
    "      #pragma omp target teams map(tofrom: d[0:N])\n",
    "      exp_pi_diff(d,my_pi);\n",
    "                                           // value should be near 1\n",
    "      printf(\"d[N-1] = %20.14f\\n\",d[N-1]); // ...= 1.00000000000311\n",
    "\n",
    "      exp_pi_diff(d,my_pi);                // value should be near 1\n",
    "      printf(\"d[N-1] = %20.14f\\n\",d[N-1]); // ...= 1.00000000000311\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!!%compiler: gfortran\n",
    "!!%cflags: -fopenmp\n",
    "\n",
    "! name: metadirective.3\n",
    "! type: F-free\n",
    "! version: omp_5.2\n",
    "module params\n",
    "   integer, parameter :: N=1000\n",
    "   DOUBLE PRECISION, PARAMETER::M_PI=4.0d0*DATAN(1.0d0)\n",
    "                                     ! 3.1415926535897932_8\n",
    "end module\n",
    "\n",
    "\n",
    "subroutine exp_pi_diff(d,    my_pi)\n",
    "  use params\n",
    "  implicit none\n",
    "  integer          ::  i\n",
    "  double precision ::  d(N), my_pi\n",
    "  !$omp declare target\n",
    "\n",
    "  !$omp   metadirective &\n",
    "  !$omp&      when( construct={target}: distribute parallel do )  &\n",
    "  !$omp&      otherwise(                parallel do simd )\n",
    "\n",
    "  do i = 1,size(d)\n",
    "     d(i) = exp( (M_PI-my_pi)*i )\n",
    "  end do\n",
    "\n",
    "end subroutine\n",
    "\n",
    "program main\n",
    "  ! Calculates sequence of exponentials: (M_PI-my_pi) * index\n",
    "  ! M_PI is from usual way, and my_pi is user provided.\n",
    "  ! Fortran Standard does not provide PI\n",
    "\n",
    "  use params\n",
    "  implicit none\n",
    "  double precision   :: d(N)\n",
    "  double precision   :: my_pi=3.14159265358979d0\n",
    "\n",
    "      !$omp target teams map(from: d)\n",
    "      call exp_pi_diff(d,my_pi)\n",
    "      !$omp end target teams\n",
    "                                  ! value should be near 1\n",
    "      print*, \"d(N) = \",d(N)      ! 1.00000000000311\n",
    "\n",
    "      call exp_pi_diff(d,my_pi) ! value should be near 1\n",
    "      print*, \"d(N) = \",d(N)      ! 1.00000000000311\n",
    "\n",
    "end program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The __user__ selector set can be used in a metadirective to select directives at execution time when the  __condition(__  _boolean-expr_  __)__ selector expression is not a constant expression. In this case it is a  _dynamic_  trait set, and the selection is made at run time, rather than at compile time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following example the  _foo_  function employs the __condition__ selector to choose a device for execution at run time.  In the  _bar_  routine metadirectives are nested. At the outer level a selection between serial and parallel execution in performed at run time, followed by another run time selection on the schedule kind in the inner level when the active  _construct_  trait is __parallel__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Note, the variable  _b_  in two of the \"selected'' constructs is declared private for the sole purpose  of detecting and reporting that the construct is used. Since the variable is private, its value  is unchanged outside of the construct region, whereas it is changed if the \"unselected'' construct is used.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//%compiler: clang\n",
    "//%cflags: -fopenmp\n",
    "\n",
    "/*\n",
    "* name:       metadirective.4\n",
    "* type:       C\n",
    "* version:    omp_5.2\n",
    "*/\n",
    "#define N 100\n",
    "#include <stdbool.h>\n",
    "#include   <stdio.h>\n",
    "#include     <omp.h>\n",
    "\n",
    "void foo(int *a, int n, bool use_gpu)\n",
    "{\n",
    "   int b=0;   //  use b to detect if run on gpu\n",
    "\n",
    "   #pragma omp metadirective \\\n",
    "               when( user={condition(use_gpu)}:           \\\n",
    "                     target teams distribute parallel for \\\n",
    "                     private(b) map(from:a[0:n]) )        \\\n",
    "               otherwise(                                 \\\n",
    "                     parallel for )\n",
    "   for (int i=0; i<n; i++) {a[i]=i; if(i==n-1) b=1;}\n",
    "\n",
    "   if(b==0) printf(\"PASSED 1 of 3\\n\");\n",
    "}\n",
    "\n",
    "void bar (int *a, int n, bool run_parallel, bool unbalanced)\n",
    "{\n",
    "   int b=0;\n",
    "   #pragma omp metadirective \\\n",
    "               when(user={condition(run_parallel)}: parallel)\n",
    "   {\n",
    "      if(omp_in_parallel() == 1 && omp_get_thread_num() == 0)\n",
    "      {printf(\"PASSED 2 of 3\\n\");}\n",
    "\n",
    "      #pragma omp metadirective \\\n",
    "          when( construct={parallel}, \\\n",
    "                user={condition(unbalanced)}: for schedule(guided) \\\n",
    "                                                  private(b)) \\\n",
    "          when( construct={parallel}        : for schedule(static))\n",
    "      for (int i=0; i<n; i++) {a[i]=i; if(i==n-1) b=1;}\n",
    "   }\n",
    "   // if guided b=0, because b is private\n",
    "   if(b==0) printf(\"PASSED 3 of 3\\n\");\n",
    "}\n",
    "\n",
    "void foo(int *a, int n, bool use_gpu);\n",
    "void bar(int *a, int n, bool run_parallel, bool unbalanced);\n",
    "\n",
    "int main(){\n",
    "\n",
    "   int p[N];\n",
    "   // App normally sets these, dependent on input parameters\n",
    "   bool use_gpu=true, run_parallel=true, unbalanced=true;\n",
    "\n",
    "   // Testing: set Env Var MK_FAIL to anything to fail tests\n",
    "   if(getenv(\"MK_FAIL\")!=NULL) {\n",
    "      use_gpu=false; run_parallel=false; unbalanced=false;\n",
    "   }\n",
    "\n",
    "   foo(p, N, use_gpu);\n",
    "   bar(p, N, run_parallel,unbalanced);\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!!%compiler: gfortran\n",
    "!!%cflags: -fopenmp\n",
    "\n",
    "! name: metadirective.4\n",
    "! type: F-free\n",
    "! version: omp_5.2\n",
    "subroutine foo(a, n, use_gpu)\n",
    "   integer :: n, a(n)\n",
    "   logical :: use_gpu\n",
    "\n",
    "   integer :: b=0   !! use b to detect if run on gpu\n",
    "\n",
    "   !$omp metadirective &\n",
    "   !$omp&            when(user={condition(use_gpu)}:           &\n",
    "   !$omp&                 target teams distribute parallel for &\n",
    "   !$omp&                 private(b) map(from:a(1:n)) )        &\n",
    "   !$omp&            otherwise(                                &\n",
    "   !$omp&                 parallel do)\n",
    "   do i = 1,n; a(i)=i; if(i==n) b=1; end do\n",
    "\n",
    "   if(b==0) print *, \"PASSED 1 of 3\"  ! bc b is firstprivate for gpu run\n",
    "end subroutine\n",
    "\n",
    "subroutine bar (a, n, run_parallel, unbalanced)\n",
    "   use omp_lib, only : omp_get_thread_num\n",
    "   integer :: n, a(n)\n",
    "   logical :: run_parallel, unbalanced\n",
    "\n",
    "   integer :: b=0\n",
    "   !$omp begin metadirective when(user={condition(run_parallel)}: parallel)\n",
    "\n",
    "    if(omp_in_parallel() == 1 .and. omp_get_thread_num() == 0) &\n",
    "       print *,\"PASSED 2 of 3\"\n",
    "\n",
    "    !$omp metadirective &\n",
    "    !$omp&  when(construct={parallel}, user={condition(unbalanced)}: &\n",
    "    !$omp&         for schedule(guided) private(b)) &\n",
    "    !$omp&  when(construct={parallel}: for schedule(static))\n",
    "    do i = 1,n; a(i)=i; if(i==n) b=1; end do\n",
    "\n",
    "   !$omp end metadirective\n",
    "\n",
    "   if(b==0) print *, \"PASSED 3 of 3\"   !!if guided, b=0 since b is private\n",
    "end subroutine\n",
    "\n",
    "program meta\n",
    "   use omp_lib\n",
    "   integer, parameter :: N=100\n",
    "   integer :: p(N)\n",
    "   integer :: env_stat\n",
    "                !! App normally sets these, dependent on input parameters\n",
    "   logical ::  use_gpu=.true., run_parallel=.true., unbalanced=.true.\n",
    "\n",
    "                !! Testing: set Env Var MK_FAIL to anything to fail tests\n",
    "   call get_environment_variable('MK_FAIL',status=env_stat)\n",
    "   if(env_stat /= 1) then                ! status =1 when not set!\n",
    "      use_gpu=.false.; run_parallel=.false.; unbalanced=.false.\n",
    "   endif\n",
    "\n",
    "\n",
    "   call foo(p, N, use_gpu)\n",
    "   call bar(p, N, run_parallel,unbalanced)\n",
    "\n",
    "end program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metadirectives can be used in conjunction with templates as shown in the C++ code below. Here the template definition generates two versions of the Fibonacci function. The  _tasking_  boolean is used in the __condition__ selector to enable tasking. The true form implements a parallel version with __task__ and __taskwait__ constructs as in the  _tasking.4.c_  code in Section 5.1. The false form implements a serial version without any tasking constructs. Note that the serial version is used in the parallel function for optimally processing numbers less than 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//%compiler: clang\n",
    "//%cflags: -fopenmp\n",
    "\n",
    "/*\n",
    "* name:       metadirective.5\n",
    "* type:       C++\n",
    "* version:    omp_5.0\n",
    "*/\n",
    "#include <stdio.h>\n",
    "\n",
    "// revised Fibonacci from tasking.4.c example\n",
    "\n",
    "template <bool tasking>\n",
    "int fib(int n) {\n",
    "  int i, j;\n",
    "  if (n<2) {\n",
    "    return n;\n",
    "  } else if ( tasking && n<8 ) { // serial/taskless cutoff for n<8\n",
    "    return fib<false>(n);\n",
    "  } else {\n",
    "    #pragma omp metadirective \\\n",
    "                when(user={condition(tasking)}: task shared(i))\n",
    "    {\n",
    "      i=fib<tasking>(n-1);\n",
    "    }\n",
    "    #pragma omp metadirective \\\n",
    "                when(user={condition(tasking)}: task shared(j))\n",
    "    {\n",
    "      j=fib<tasking>(n-2);\n",
    "    }\n",
    "    #pragma omp metadirective \\\n",
    "                when(user={condition(tasking)}: taskwait)\n",
    "    return i+j;\n",
    "  }\n",
    "}\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "  int n = 15;\n",
    "  #pragma omp parallel\n",
    "  #pragma omp single\n",
    "  {\n",
    "    printf(\"fib(%i) = %i\\n\", n, fib<true>(n));\n",
    "  }\n",
    "  return 0;\n",
    "}\n",
    "// OUTPUT:\n",
    "// fib(15) = 610"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Native",
   "language": "native",
   "name": "native"
  },
  "language_info": {
   "file_extension": ".c",
   "mimetype": "text/plain",
   "name": "c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
